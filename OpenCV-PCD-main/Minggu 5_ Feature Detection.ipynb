{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kOh5ObF8nBKJ"
   },
   "source": [
    "# **Minggu 5: Feature Detection**\n",
    "\n",
    "\n",
    "(*Tutorial Rujukan: [Dokumentasi OpenCV untuk Feature Detection](https://docs.opencv.org/3.4/db/d27/tutorial_py_table_of_contents_feature2d.html)*)\n",
    "\n",
    "\n",
    "Pada bagian ini kita akan menggunakan teknik deteksi fitur dan matching untuk melakukan beberapa pengolahan citra dan memperoleh informasi. Ingat bahwa pengolahan citra perlu dilakukan secara bertahap dengan teknik yang boleh jadi berbeda pada kondisi yang berbeda. Untuk itu ingat kembali pelajaran pada minggu-minggu sebelumnya sebelum melanjutkan pada materi di Minggu ini.\n",
    "\n",
    "Contoh gambar untuk latihan pada minggu ini tersedia pada eLOK mata kuliah PCD. Unduh tiap gambar, kemudian unggah pada Google Colab menggunakan cara yang telah diberikan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lovDwU0VS1az",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Review: Ekstraksi objek pada citra\n",
    "\n",
    "Pada saat melihat sebuah foto atau gambar digital, manusia dapat dengan mudah membedakan objek yang digambarkan pada foto tersebut. Sebagai contoh, dari gambar berikut:\n",
    "\n",
    "![alt text](https://drive.google.com/uc?id=1kc8QA4GIHqaQusFlcGd91cUNnb3nr7GU)\n",
    "\n",
    "Manusia dapat dengan mudah membedakan jeruk dan daun, jeruk yang dekat dengan yang jauh, serta menghitung jumlah jeruk yang ada, misalnya.\n",
    "\n",
    "Untuk komputer, hal ini menjadi kompleks karena komputer hanya melihat serangkaian pixel, tanpa kemampuan untuk memisahkan fitur tersebut. \n",
    "\n",
    "Pada [pertemuan sebelumnya](https://colab.research.google.com/drive/1To2FZnLbxdhRSPW3lZlUQymaV2T5lF_m), telah dibahas mengenai cara 'mengajarkan' komputer agar mampu melihat dan membedakan warna (Hue) sehingga dapat digunakan untuk ekstraksi fitur. Pada [minggu selanjutnya](https://colab.research.google.com/drive/1FpvJQnGb3_A85oktAXJOzGYG24DK26u1) juga telah dibahas mengenai metode filtering dan thresholding yang dapat digunakan untuk menonjolkan **tepi** sebuah objek sehingga dapat dilakukan ekstraksi fitur, misalnya delineasi garis pantai.\n",
    "\n",
    "![alt text](https://slideplayer.com/slide/14894726/91/images/6/Images+as+functions%E2%80%A6+Edges+look+like+steep+cliffs.jpg)\n",
    "\n",
    "Dengan menggunakan nilai piksel pada sebuah citra digital, kita dapat memberikan informasi pada komputer agar dapat mengenali suatu objek. Namun bagaimana dengan kedalaman objek tersebut? Pembahasan minggu ini merupakan pengantar untuk materi *depth reconstruction* melalui pengolahan citra digital.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9jUkfgmpjR26"
   },
   "source": [
    "## Apa itu Fitur?\n",
    "\n",
    "'Fitur' merupakan bagian dari citra yang dapat diidentifikasi dengan mudah oleh komputer. Sebagai contoh, pada gambar berikut: \n",
    "\n",
    "![alt text](https://drive.google.com/uc?id=1lDujYsNKdilG_d-Uv4gt0hzoPzBKDZ6q)\n",
    "\n",
    "Manakah yang merupakan 'fitur' yang mudah untuk diidentifikasi?\n",
    "\n",
    "Jawabnya adalah ujung persegi panjang yang ditandai oleh kotak berwarna merah. Kedua fitur lain cukup sulit untuk diidentifikasi:\n",
    "*   Kotak warna biru dapat berada pada posisi manapun di dalam persegi panjang warna hijau\n",
    "*   kotak warna hitam dapat berada dimana saja selama berada pada tepian persegi panjang.\n",
    "\n",
    "Dengan demikian, sebuah citra dapat dilatih untuk mencari titik-titik yang mudah dilacak (*Good Features To Track*) dengan membuat kategori untuk tiap piksel dengan tetangga piksel masing-masing. \n",
    "\n",
    "Terdapat beberapa algoritma untuk melakukan deteksi pojok ('Corner Detector') dari sebuah citra digital. Beberapa yang cukup populer adalah:\n",
    "\n",
    "*   [Harris Corner Detector](https://docs.opencv.org/3.4/dc/d0d/tutorial_py_features_harris.html)\n",
    "*   [Shi-Tomasi dan Good Features to Track](https://docs.opencv.org/3.4/d4/d8c/tutorial_py_shi_tomasi.html)\n",
    "\n",
    "Lakukan latihan berikut untuk memahami mengenai Good Features to Track pada sebuah Citra Digital\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_JHulpmeoeFN"
   },
   "source": [
    "### Latihan 1: Menggunakan Corner Detector\n",
    "\n",
    "Lakukan latihan berikut menggunakan kedua metode yang tersedia pada OpenCV (Harris Corner dan Shi-Tomasi). Gunakan gambar yang berbeda dan bandingkan jumlah corner yang berhasil dideteksi oleh kedua algoritma tersebut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t0N_syNomvbg",
    "outputId": "124ebecf-5d56-4ae0-ddeb-271a766ce9d3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!wget https://pns2019.github.io/images/Lenna.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 602
    },
    "id": "qYui-Wh_orjz",
    "outputId": "fd0cef8b-1ff2-4990-d945-6228ba87a98d"
   },
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.5) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# gunakan gambar yang disediakan di eLOK\u001b[39;00m\n\u001b[0;32m      8\u001b[0m img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgedungpusat.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 9\u001b[0m gray \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcvtColor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCOLOR_BGR2GRAY\u001b[49m\u001b[43m)\u001b[49m \n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# deteksi pojok dengan GFTT\u001b[39;00m\n\u001b[0;32m     13\u001b[0m corners \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mgoodFeaturesToTrack(gray,\u001b[38;5;241m1000\u001b[39m,\u001b[38;5;241m0.01\u001b[39m,\u001b[38;5;241m10\u001b[39m)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.5.5) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "# Menggunakan Shi-Tomasi GFTT untuk deteksi ujung (corner detection)\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# gunakan gambar yang disediakan di eLOK\n",
    "img = cv2.imread('gedungpusat.jpg')\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY) \n",
    "\n",
    "\n",
    "# deteksi pojok dengan GFTT\n",
    "corners = cv2.goodFeaturesToTrack(gray,1000,0.01,10)\n",
    "corners = np.int0(corners)\n",
    "\n",
    "# menampilkan jumlah titik terdeteksi dengan fungsi numpy (np.ndarray.shape)\n",
    "print(\"jumlah titik terdeteksi = \", corners.shape[0])\n",
    "\n",
    "# untuk ditampilkan di Matplotlib, urutan band dibalik\n",
    "rgb = cv2.cvtColor(img,cv.COLOR_BGR2RGB)\n",
    "\n",
    "# perbesar ukuran hasil plotting \n",
    "plt.rcParams[\"figure.figsize\"] = (20,20)\n",
    "\n",
    "# untuk tiap pojok yang terdeteksi, munculkan pada gambar\n",
    "for i in corners:\n",
    "    x,y = i.ravel()\n",
    "    cv2.circle(rgb,(x,y),3,255,-1)\n",
    "plt.imshow(rgb),plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aX78PSX_oZdW"
   },
   "source": [
    "## Deteksi Keypoints (Feature Detection)\n",
    "\n",
    "*(Rujukan: http://www.fossreview.com/2018/06/studying-digital-image-with-opencv4.html)*\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "Deteksi ujung (corner detection) dapat digunakan untuk \n",
    "mengidentifikasi fitur pada satu foto dengan baik. Namun demikian, metode ini kurang dapat digunakan dengan baik apabila diperlukan untuk mengidentifikasi titik yang sama pada foto yang berbeda. Kebutuhan ini akan kita jumpai pada saat kita mencari hubungan geometri pada dua buah foto, misalnya (ingat materi [minggu ke-4](https://colab.research.google.com/drive/1ZmddpA9v5dnzKJ8Up_So0AfjKjroOojZ)).\n",
    "\n",
    "Sebagai contoh, pada gambar berikut:\n",
    "\n",
    "![alt text](https://drive.google.com/uc?id=1c3g2BTFgSunu2BXqKLViVkr6u3pjT8Of)\n",
    "\n",
    "Corner detection tidak akan banyak berguna untuk mencari titik-titik yang sama dan berpasangan pada kedua buah gambar (bayangkan '*tie-points*' pada fotogrametri). Hal ini disebabkan karena gambar kedua memiliki posisi yang berbeda (mengalami rotasi, translasi dan/atau skala), sehingga deteksi ujung tidak dapat digunakan. \n",
    "\n",
    "Gambar berikut menunjukkan kelemahan corner detector apabila digunakan pada gambar dengan perubahan skala (misalnya beda tinggi terbang foto udara)\n",
    "\n",
    "![alt text](https://opencv-python-tutroals.readthedocs.io/en/latest/_images/sift_scale_invariant.jpg)\n",
    "\n",
    "Pada pelajaran minggu sebelumnya telah diberikan contoh bahwa dari beberapa **titik sekutu** pada dua buah foto dapat dicari matriks, atau **HOMOGRAPHY** yang menyatakan hubungan antara kedua sistem foto tersebut. Dengan demikian, permasalahannya adalah bagaimana mencari titik-titik yang dapat dideteksi pada kedua buah foto sekaligus dapat dihubungkan antara titik satu dengan yang lain?\n",
    "\n",
    "Untuk itu, dikembangkan suatu metode untuk melakukan deteksi *keypoint* pada tiap foto. **Keypoint** dapat disebut sebagai sebuah 'basisdata' untuk tiap titik dengan karakteristik tertentu berdasarkan atas nilai piksel tetangganya. Dengan membentuk basisdata titik yang cukup detil, dua buah titik dapat saling dipasangkan apabila memiliki kemiripan yang cukup. Dengan demikian, matriks homography dapat dihitung dan rekonstruksi posisi foto dapat dilakukan sebagaimana materi yang telah disampaikan sebelumnya.\n",
    "\n",
    "Pada OpenCV, terdapat beberapa fungsi deteksi keypoints, antara lain:\n",
    "\n",
    "*   [SIFT (Scale-Invariant Feature Transform)](https://docs.opencv.org/3.4/da/df5/tutorial_py_sift_intro.html). Merupakan metode yang paling terkenal dan banyak digunakan\n",
    "*   [SURF (Speeded-Up Robust Feature)](https://docs.opencv.org/3.4/df/dd2/tutorial_py_surf_intro.html).\n",
    "* [FAST](https://docs.opencv.org/3.4/df/d0c/tutorial_py_fast.html) \n",
    "* [BRIEF (Binary Robust Independent Elementary Features)](https://docs.opencv.org/3.4/dc/d7d/tutorial_py_brief.html). Merupakan descriptor yang digunakan untuk menghitung hasil deteksi secara lebih efisien. BRIEF seringkali dipasangkan dengan FAST.\n",
    "* [ORB (Oriented FAST and Rotated BRIEF)](https://docs.opencv.org/3.4/d1/d89/tutorial_py_orb.html), merupakan alternatif gratis untuk SIFT dan SURF (keduanya memiliki paten)\n",
    "* [A-KAZE](https://docs.opencv.org/3.4/db/d70/tutorial_akaze_matching.html). Salah satu feature detector terbaru yang banyak digunakan di software SfM Opensource\n",
    "\n",
    "\n",
    "Fungsi-fungsi di atas dapat dipanggil dengan menggunakan fungsi features2d pada OpenCV sebagai berikut:\n",
    "\n",
    "```\n",
    "sift = cv2.xfeatures2d.SIFT_create()\n",
    "surf = cv2.xfeatures2d.SURF_create()\n",
    "orb = cv2.ORB_create(nfeatures=1500)\n",
    "\n",
    "# FAST dan BRIEF\n",
    "# FAST detector\n",
    "star = cv.xfeatures2d.StarDetector_create()\n",
    "# BRIEF extractor\n",
    "brief = cv.xfeatures2d.BriefDescriptorExtractor_create()\n",
    "```\n",
    "\n",
    "Karena algoritma SIFT dan SURF dipatenkan dan berbayar sedangkan OpenCV adalah perangkat lunak opensource, mulai OpenCV versi 4 semua fungsi tersebut dipisahkan dari modul utama OpenCV. Dengan demikian, untuk menggunakan fungsi tersebut dapat digunakan OpenCV versi lama (Versi 3) yang masih mengandung modul SIFT dan SURF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v8qmPjLh5H4c"
   },
   "source": [
    "### Latihan 2: Menggunakan ORB dan KAZE\n",
    "\n",
    "ORB dan KAZE merupakan contoh feature detector yang bersifat *opensource*, sehingga dapat digunakan secara gratis pada OpenCV. \n",
    "\n",
    "Lakukan latihan berikut dengan gambar yang berbeda. Apabila script menggunakan gambar grayscale, tampilkan gambar berwarna dengan menggunakan Matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 602
    },
    "id": "CPrpfChNS0BY",
    "outputId": "4dd3ad61-3109-4b26-ae69-ec7f5205df1d"
   },
   "outputs": [],
   "source": [
    "# Mendownload gambar Lenna untuk contoh\n",
    "#!wget https://pns2019.github.io/images/Lenna.png\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# memanggil gambar berwarna\n",
    "img = cv2.imread('gedungpusat.jpg')\n",
    "\n",
    "# cara lain memanggil grayscale dari gambar\n",
    "#img = cv2.imread('gedungpusat.jpg',0)\n",
    "gray= cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# mendefinisikan KAZE descriptor\n",
    "kaze = cv2.KAZE_create()\n",
    "kp = kaze.detect(gray)\n",
    "\n",
    "#kps = sorted(kp, key=lambda x: -x.response)[:32]\n",
    "\n",
    "# computing descriptors vector\n",
    "kp, dsc = kaze.compute(gray, kp)\n",
    "\n",
    "# berapa titik yang terdeteksi?\n",
    "print(\"jumlah titik terdeteksi = \", len(kp))\n",
    "\n",
    "# menggambar keypoint yang berhasil diidentifikasi\n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "img2 = cv2.drawKeypoints(img_rgb, kp, None, color=(0,255,0), flags=0)\n",
    "plt.imshow(img2), plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sgwyg1OK2jZi"
   },
   "source": [
    "Contoh di atas menggunakan KAZE untuk mendeteksi titik. Ingat bahwa **keypoint** yang dihasilkan di proses ini berbeda dengan **corner** yang kita peroleh pada saat menggunakan corner detector seperti Harris di atas. Keypoint merupakan basisdata titik yang juga mengandung informasi mengenai piksel di sekitarnya sehingga kita dapat memasangkan tiap keypoint ini meskipun dideteksi pada foto yang berbeda.\n",
    "\n",
    "Contoh di bawah menggunakan ORB untuk mendeteksi keypoint. Apa yang dapat Anda amati?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 602
    },
    "id": "Cy_b0lCV5Y8R",
    "outputId": "db9d0ef3-8bf4-4687-a9bd-f9b3b9b5f805"
   },
   "outputs": [],
   "source": [
    "# Latihan ORB\n",
    "\n",
    "import numpy as np\n",
    "import cv2 \n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# membaca citra\n",
    "img = cv2.imread('gedungpusat.jpg',0)\n",
    "\n",
    "# membuat ORB detector\n",
    "orb = cv2.ORB_create()\n",
    "\n",
    "# kp: variabel untuk menyimpan keypoint yang berhasil dideteksi\n",
    "kp = orb.detect(img,None)\n",
    "\n",
    "# menghitung deskriptor\n",
    "# kp = keypoints\n",
    "# des = descriptor\n",
    "kp, des = orb.compute(img, kp)\n",
    "\n",
    "# berapa jumlah titik terdeteksi?\n",
    "print(\"jumlah titik terdeteksi = \", len(kp))\n",
    "\n",
    "# menggambar keypoint yang berhasil diidentifikasi \n",
    "img2 = cv2.drawKeypoints(img_rgb, kp, None, color=(0,255,0), flags=0)  # img_rbg dari variabel sebelumnya di atas\n",
    "plt.imshow(img2), plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nXlgmtFc47PN"
   },
   "source": [
    "### Latihan 3: Menggunakan SIFT dan SURF\n",
    "\n",
    "Berbeda dengan ORB dan KAZE (dan beberapa algoritma keypoint-detector lain) yang diberikan dalam bentuk open source, SIFT dan SURF merupakan algoritma yang telah dipatenkan, sehingga dihapus pada OpenCV versi 4 ke atas dan dirubah menjadi *community module*. \n",
    "\n",
    "Untuk keperluan praktek ini, untuk menggunakan modul SIFT dan SURF, terlebih dahulu kita harus uninstall OpenCV bawaan dari Google Colab, kemudian melakukan instalasi versi OpenCV yang lebih rendah. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 513
    },
    "id": "oOWe7MZ7bWlL",
    "outputId": "efa67a85-5336-446b-812e-f2f5ec73055e"
   },
   "outputs": [],
   "source": [
    "# untuk menjalankan fungsi detektor SIFT, SURF dan ORB pada OpenCV,\n",
    "# terlebih dahulu uninstall OpenCV versi 4 yang secara default terinstall\n",
    "# pada Google Colab, kemudian lakukan kembali instalasi versi OpenCV \n",
    "# yang lebih rendah sehingga fungsi SIFT dkk dapat digunakan\n",
    "\n",
    "!pip uninstall opencv-python -y\n",
    "\n",
    "# Downgrade versi OpenCV menjadi versi 3\n",
    "!pip install opencv-contrib-python==3.4.2.17 --force-reinstall\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TTS0mQb_82ob"
   },
   "source": [
    "Setelah melakukan instalasi seperti di atas, kita harus melakukan restart pada Runtime Google Colab agar versi OpenCV yang baru (versi 3) dapat kita gunakan. Setelah restart, lakukan pengecekan versi opencv terinstall seperti berikut:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qP0pVHY883uQ",
    "outputId": "c5da87f5-8769-4462-cdda-039761b6ca4c"
   },
   "outputs": [],
   "source": [
    "# cek versi opencv sekarang \n",
    "import cv2\n",
    "print(cv2.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3xEki3Vo_lRu"
   },
   "source": [
    "Setelah OpenCV versi 3 berhasil diinstal, barulah fungsi berikut dapat dijalankan:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 602
    },
    "id": "O12YeRaJ_a0E",
    "outputId": "16d1c80f-7155-4637-c083-503ac1c2d545"
   },
   "outputs": [],
   "source": [
    "# Melakukan deteksi keypoint dengan algoritma SIFT\n",
    "\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img = cv2.imread('gedungpusat.jpg')\n",
    "# konversi ke warna abu2 agar menjadi satu band\n",
    "gray= cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# menghitung fitur dengan SIFT\n",
    "sift = cv2.xfeatures2d.SIFT_create()\n",
    "kp = sift.detect(gray, None)\n",
    "\n",
    "# berapa jumlah titik terdeteksi?\n",
    "print(\"jumlah titik terdeteksi= \", len(kp))\n",
    "\n",
    "# perbesar ukuran hasil plotting \n",
    "plt.rcParams[\"figure.figsize\"] = (20,20)\n",
    "\n",
    "# menggambar keypoint yang berhasil diidentifikasi \n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "img3 =cv2.drawKeypoints(img_rgb,kp,img,flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "plt.imshow(img3), plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IahMhemFAP_8"
   },
   "source": [
    "Berbeda dengan ORB dan KAZE di atas, SIFT menggunakan definisi keypoint yang terlihat lebih beragam: selain posisi dan piksel di sekeliling titik, SIFT juga mengidentifikasi *orientasi* dari tiap keypoint, sehingga memungkinkan fitur yang ter-rotasi (misalnya foto udara) untuk dapat dipasangkan satu dengan yang lain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_k36G3pMBNyB"
   },
   "source": [
    "Berdasarkan contoh-contoh di atas, coba buat detektor keypoint dengan menggunakan SURF. Perintah untuk SURF adalah seperti berikut:\n",
    "\n",
    "```\n",
    "# definisi SURF\n",
    "surf = cv2.SURF(400)\n",
    "\n",
    "# mencari dan menghitung keypoint\n",
    "kp, des = surf.detectAndCompute(img,None)\n",
    "\n",
    "```\n",
    "\n",
    "Bagaimana perbandingan jumlah kypoint yang dideteksi berdasarkan semua algoritma yang telah disebutkan di atas?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OAGLhJllucS5"
   },
   "source": [
    "## Feature Matching\n",
    "\n",
    "Rujukan: https://pysource.com/2018/03/23/feature-matching-brute-force-opencv-3-4-with-python-3-tutorial-26/\n",
    "\n",
    "\n",
    "Apabila feature detector digunakan untuk mencari titik yang dapat dipasangkan, maka **Feature Matching** digunakan untuk memasangkan masing-masing keypoint yang sudah terdeteksi pada satu citra dengan titik titik yang memiliki kesamaan karakter pada citra lain. Dengan demikian, dapat dikatakan bahwa hasil dari feature matching adalah **Tie-Points** pada sebuah proses fotogrametri.\n",
    "\n",
    "![alt text](https://docs.opencv.org/3.4/matcher_flann.jpg)\n",
    "\n",
    "Pada Gambar di atas, lingkaran berwarna merah merupakan fitur (keypoints) yang dideteksi dengan menggunakan *Feature Detector* pada OpenCV, sedangkan garis-garis berwarna hijau merupakan titik-titik yang berhasil dipasangkan berdasarkan atas kesamaan karakteristik (*feature matching*).\n",
    "\n",
    "Terdapat beberapa algoritma yang berbeda pula pada metode Feature Matching, antara lain:\n",
    "\n",
    "\n",
    "*   Brute-Force Matching\n",
    "*   FLANN\n",
    "\n",
    "(Panduan untuk keduanya dapat dilihat [di sini](https://docs.opencv.org/3.4/dc/dc3/tutorial_py_matcher.html))\n",
    "\n",
    "Penggunaan kedua model feature matching tersebut perlu disesuaikan dengan algoritma keypoint detector yang digunakan.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q5C6zCwo98v_"
   },
   "source": [
    "### Latihan 4: Feature Detection and Matching\n",
    "\n",
    "Setelah memperoleh 'basisdata' keypoint, langkah selanjutnya adalah memasangkan masing-masing titik keypoint tersebut pada pasangannya yang memiliki kesamaan karakteristik. Contoh di bawah adalah bagaimana Feature Matching digunakan untuk memasangkan titik-titik keypoints yang berhasil ditemukan:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 483
    },
    "id": "oIYehW_0ZGlx",
    "outputId": "b94ab668-8f41-4e87-9851-6d803ee0846b"
   },
   "outputs": [],
   "source": [
    "# Contoh Script untuk feature detection and Matching\n",
    "# Modifikasi script ini untuk mencoba metode yang berbeda \n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Gunakan gambar dari eLOK\n",
    "img1 = cv2.imread('webarebears.jpg')          # gambar yang dituju\n",
    "img2 = cv2.imread('ice_bear.jpg')             # gambar yang dicari\n",
    "gray1= cv2.cvtColor(img1,cv2.COLOR_BGR2GRAY)\n",
    "gray2= cv2.cvtColor(img2,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Menggunakan Detector SIFT\n",
    "sift = cv2.xfeatures2d.SIFT_create()\n",
    "\n",
    "# Mencari Keypoint dengan SIFT\n",
    "kp1, des1 = sift.detectAndCompute(gray1,None)\n",
    "kp2, des2 = sift.detectAndCompute(gray2,None)\n",
    "\n",
    "# Melakukan Matching dari hasil deteksi keypoints menggunakan\n",
    "# BruteForce Matcher\n",
    "bf = cv2.BFMatcher()\n",
    "matches = bf.knnMatch(des1,des2, k=2)\n",
    "\n",
    "# Uji rasio matching sederhana\n",
    "good = []\n",
    "for m,n in matches:\n",
    "    if m.distance < 0.5*n.distance:\n",
    "        good.append([m])\n",
    "img3 = None\n",
    "\n",
    "# menggambar hasil match pada gambar baru (IMG3)\n",
    "img3 = cv2.drawMatchesKnn(img1,kp1,img2,kp2,good,img3,flags=2)\n",
    "plt.imshow(cv2.cvtColor(img3, cv2.COLOR_BGR2RGB)),plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GfXpgBZ_I8a2"
   },
   "source": [
    "Dari contoh di atas dapat dilihat bahwa dengan metode deteksi keypoint menggunakan SIFT kita dapat melakukan matching pada objek yang mengalami rotasi (ingat bahwa *SIFT=Scale-Invariant Feature Transform*). Aplikasi dari algoritma ini untuk bidang fotogrametri adalah pada deteksi titik tie-points secara otomatis pada dua buah foto yang bertampalan, sedangkan pada bidang remote sensing, metode ini digunakan dalam pembuatan mosaik otomatis untuk mendukung metode registrasi citra, semisal dengan RPC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DiegQxnnx_xP"
   },
   "source": [
    "## Template Matching\n",
    "\n",
    "Dari pelajaran di atas serta contoh-contoh praktikum beberapa minggu sebelumnya, kita telah melihat bagaimana algoritma level rendah seperti transformasi colorspace, edge detection, feature detection dan matching dapat sangat berguna untuk memperoleh berbagai informasi yang kita inginkan pada sebuah citra. Dengan memahami cara kerja dari masing-masing algoritma tersebut kita akan lebih mudah mengetahui bagaimana perangkat lunak pengolahan citra bekerja di belakang layar serta bagaimana melakukan pengaturan parameter yang dapat digunakan untuk mengoptimalkan hasil pemrosesan citra yang kita inginkan. \n",
    "\n",
    "Pada bagian ini kita akan menggunakan salah satu fungsi OpenCV yang digunakan untuk meringkas beberapa langkah di atas, yaitu deteksi keypoint, matching dan deteksi tepi untuk mendeteksi posisi wajah dari serangkaian gambar. Algoritma ini disebut sebagai 'Template Matching'.  OpenCV menyediakan fungsi `cv2.matchTemplate()` untuk keperluan Template Matching ini dengan berbagai metode deteksi berdasarkan tingkat kemiripan antara `template` atau gambar yang dicari dengan objek pada gambar yang tersedia , misalnya dengan menghitung rerata korelasi antar nilai piksel pada template tersebut dengan objek yang dicari. Latihan berikut menunjukkan aplikasi dari berbagai metode tersebut untuk mencari gambar yang diberikan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ECZBKsrUYa4Z"
   },
   "source": [
    "Kita panggil terlebih dahulu kedua gambar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 511
    },
    "id": "qtrqRcVuYeRr",
    "outputId": "88d7e3f9-07cf-4c91-8af6-80d440d0989e"
   },
   "outputs": [],
   "source": [
    "# tampilkan kedua gambar\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# panggil dan konversi warna agar sesuai dengan Matplotlib\n",
    "einstein = cv2.imread('einstein.png')\n",
    "einstein =  cv2.cvtColor(einstein, cv2.COLOR_BGR2RGB) # simpan dengan nama yang sama = ditumpuk\n",
    "\n",
    "# panggil dan konversi warna agar sesuai dengan Matplotlib\n",
    "solvay = cv2.imread('solvayconference.jpg')\n",
    "solvay =  cv2.cvtColor(solvay, cv2.COLOR_BGR2RGB) \n",
    "\n",
    "plt.subplot(121),plt.imshow(einstein), plt.title('Einstein')\n",
    "plt.subplot(122),plt.imshow(solvay), plt.title('Solvay Conference 1927')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xQ_Jm2v2YfWP"
   },
   "source": [
    "Selanjutnya, lakukan Template Matching pada gambar Einstein dan Gambar Solvay Conference untuk mencari di mana Einstein duduk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "K0Y3NJIhyDwm",
    "outputId": "ca374b95-4fb4-4db8-b359-e5e2eb2024da"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img = cv2.imread('solvayconference.jpg',0)\n",
    "img2 = img.copy()\n",
    "template = cv2.imread('einstein.png',0)\n",
    "w, h = template.shape[::-1]\n",
    "\n",
    "# All the 6 methods for comparison in a list\n",
    "methods = ['cv2.TM_CCOEFF', 'cv2.TM_CCOEFF_NORMED', 'cv2.TM_CCORR',\n",
    "            'cv2.TM_CCORR_NORMED', 'cv2.TM_SQDIFF', 'cv2.TM_SQDIFF_NORMED']\n",
    "\n",
    "# perbesar ukuran hasil plotting \n",
    "plt.rcParams[\"figure.figsize\"] = (15,15)\n",
    "\n",
    "for met in methods:\n",
    "    img = img2.copy()\n",
    "    method = eval(met)\n",
    "\n",
    "    # menggunakan template matching\n",
    "    res = cv2.matchTemplate(img,template,method)\n",
    "\n",
    "    # mencari ukuran citra template untuk menggambar kotak\n",
    "    min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(res)\n",
    "\n",
    "    # metode TM_SQDIFF dan TM_SQDIFF_NORMED menggunakan persamaan yang sedikit berbeda\n",
    "    # sehingga dibuatkan fungsi khusus untuk mengambil nilai minimum\n",
    "    if method in [cv2.TM_SQDIFF, cv2.TM_SQDIFF_NORMED]:\n",
    "        top_left = min_loc\n",
    "    else:\n",
    "        top_left = max_loc\n",
    "    bottom_right = (top_left[0] + w, top_left[1] + h)\n",
    "\n",
    "    \n",
    "    \n",
    "    # buat persegi pada lokasi yang ditemukan\n",
    "    cv2.rectangle(img, top_left, bottom_right, 255, 2) # 2 adalah ketebalan garis kotak\n",
    "\n",
    "    print(\"hasil metode\", met, \": \" )\n",
    "    plt.subplot(121),plt.imshow(res,cmap = 'gray')\n",
    "    plt.title('Hasil matching'), plt.xticks([]), plt.yticks([])\n",
    "    plt.subplot(122),plt.imshow(img,cmap = 'gray')\n",
    "    plt.title('Lokasi terdeteksi'), plt.xticks([]), plt.yticks([])\n",
    "    \n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X0re-CIUY-De"
   },
   "source": [
    "Pada contoh di atas, beberapa metode matching memberikan hasil yang lebih baik dibanding yang lain. Untuk tiap kondisi yang berbeda boleh jadi penggunaan parameter yang berbeda akan memberikan hasil yang lebih baik. Demikian pula, preprocessing (seperti melakukan deteksi tepi) biasanya akan membantu dalam proses matching seperti ini.\n",
    "\n",
    "> Apa yang terjadi jika kita menggunakan foto Einstein yang lain? apakah program tetap dapat mendeteksi posisinya?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oNkbPWhGRWnR"
   },
   "source": [
    "Pada bidang remote sensing, aplikasi dari Template Matching ini antara lain adalah untuk menghitung jumlah objek. Jika pada pelajaran di minggu sebelumnya kita menggunakan metode thresholding dan contouring untuk menghitung jumlah objek yang dapat ditemukan berdasarkan deteksi tepi, maka pada bagian ini kita akan menggunakan teknik template matching berdasarkan deteksi keypoint untuk mendeteksi jumlah objek. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RivTcZXHWyIh"
   },
   "source": [
    "Kita akan mencoba melakukan deteksi jumlah pohon sawit dengan algoritma sederhana di atas. Gunakan file `sawit.png` sebagai template dan `plantation.jpg` pada eLOK UGM sebagai gambar yang akan kita cari dan hitung jumlahnya. Unggah kedua file tersebut pada Google Colab seperti sebelumnya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 403
    },
    "id": "xZPpERZrXJUj",
    "outputId": "5e58cb7f-a62e-4345-a53e-2d16e7677735"
   },
   "outputs": [],
   "source": [
    "# tampilkan kedua gambar\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# panggil dan konversi warna agar sesuai dengan Matplotlib\n",
    "sawit = cv2.imread('sawit.png')\n",
    "sawit =  cv2.cvtColor(sawit, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# panggil dan konversi warna agar sesuai dengan Matplotlib\n",
    "kebun_sawit = cv2.imread('plantation.jpg')\n",
    "kebun_sawit =  cv2.cvtColor(kebun_sawit, cv2.COLOR_BGR2RGB) \n",
    "\n",
    "plt.subplot(121),plt.imshow(sawit), plt.title('sawit')\n",
    "plt.subplot(122),plt.imshow(kebun_sawit), plt.title('kebun sawit')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SPOL9_07Z6UE"
   },
   "source": [
    "Pada contoh script di bawah, kita akan menggunakan template matching untuk menentukan jumlah pohon sawit berdasarkan template sawit seperti di atas. Parameter threshold di bawah menentukan seberapa mirip keypoint yang ingin kita deteksi berdasarkan template, sehingga kita dapat merubah nilai tersebut untuk mendapatkan jumlah yang lebih optimal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "ORzmadnlVv5m",
    "outputId": "0149a719-ed67-4d61-fee1-b1e087d3a804"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from google.colab.patches import cv2_imshow\n",
    "\n",
    "## membaca gambar utuh untuk dicari\n",
    "img_rgb = cv2.imread('plantation.jpg')\n",
    "img_gray = cv2.cvtColor(img_rgb, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "## membaca template \n",
    "template = cv2.imread('sawit.png',0)\n",
    "\n",
    "## ukuran template. ukuran ini akan digunakan untuk menggambar kotak\n",
    "w, h = template.shape[::-1]\n",
    "\n",
    "# menggunakan metode COEFF-NORMALIZED\n",
    "res = cv2.matchTemplate(img_gray,template,cv2.TM_CCOEFF_NORMED)\n",
    "\n",
    "# Nilai threshold atau ambang batas deteksi kemiripan titik. \n",
    "# Lakukan eksperimen dengan merubah nilai ini\n",
    "threshold = 0.15\n",
    "loc = np.where(res >= threshold)\n",
    "\n",
    "## membuat array kosong untuk menyimpan lokasi-lokasi dari hasil deteksi\n",
    "lspoint=[]\n",
    "lspoint2=[]\n",
    "count = 0  # untuk menyimpan jumlah matching yang ditemukan\n",
    "for pt in zip(*loc[::-1]):\n",
    "\t## jika sudah ada, skip lokasi tersebut\n",
    "\tif pt[0] not in lspoint and pt[1] not in lspoint2:\n",
    "\t\t## gambar persegi warna kuning dengan ketebalan dua poin\n",
    "\t\tcv2.rectangle(img_rgb, pt, (pt[0] + w, pt[1] + h), (0,255,255), 2)\n",
    "\t\tfor i in range(((pt[0])-9), ((pt[0])+9),1):\n",
    "\t\t\t## tambahkan koordinat x ke list\n",
    "\t\t\tlspoint.append(i)\n",
    "\t\tfor k in range(((pt[1])-9), ((pt[1])+9),1):\n",
    "\t\t\t## tambahkan koordinat y ke list\n",
    "\t\t\tlspoint2.append(k)\n",
    "\t\tcount+=1 ### berapa jumlah matching yang ditemukan?\n",
    "\telse:\n",
    "\t\tcontinue\n",
    "print (\"Jumlah objek ditemukan \", count)\n",
    "\n",
    "## tampilkan dengan imshow\t\n",
    "cv2_imshow(img_rgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ffKEDdLHdCXP"
   },
   "source": [
    "Hasil dari deteksi titik menunjukkan bahwa deteksi hanya dengan mengandalkan keypoint semata ternyata tidak berhasil dengan baik. Selain bahwa tidak semua titik terdeteksi, ternyata hasil deteksi juga melenceng dari posisi yang seharusnya. Ini adalah pertanyaan untuk Anda. \n",
    "\n",
    "*Mengapa ini terjadi?*\n",
    "\n",
    "*Bagaimana cara agar hasilnya lebih baik?*\n",
    "\n",
    "*Kira-kira untuk aplikasi apakah metode ini tepat untuk digunakan?*\n",
    "\n",
    "Jawaban untuk pertanyaan-pertanyaan tersebut akan kita bahas sampai di akhir pertemuan Mata Kuliah Pengolahan Citra Digital ini."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7FBWtb_j8iXu"
   },
   "source": [
    "## Resume\n",
    "\n",
    "Feature Detector dan Feature Matching merupakan metode untuk 1) mencari dan membuat basisdata titik untuk dipasangkan, dan 2) memasangkan tiap titik berdasarkan kesamaan karakteristik tertentu. Dalam fotogrametri, kedua metode ini berguna untuk mencari **tie points** secara otomatis pada dua buah gambar stereo. Selanjutnya, setelah titik-titik dapat diidentifikasi dan dipasangkan, dapat direkonstruksi geometri pengambilan gambar kedua foto tersebut meskipun *tanpa menggunakan GCP atau posisi awal kamera*. Hal ini akan merupakan pembahasan awal mengenai SfM (Structure from Motion). Untuk lebih jelasnya, silahkan mencari sumber-sumber lain yang terkait dengan bagaimana SfM bekerja untuk melakukan rekonstruksi geometri 3D dari serangkaian foto udara yang bertampalan.\n",
    "\n",
    "![](https://raw.githubusercontent.com/magicleap/SuperGluePretrainedNetwork/master/assets/freiburg_matches.gif)\n",
    "\n",
    "\n",
    "Rangkuman algoritma yang tersedia pada OpenCV dapat dilihat pada gambar berikut:\n",
    "\n",
    "![alt text](https://drive.google.com/uc?id=1DnWKbvF5rOqXnRQhIn6Qp-aqcjsni_ik)\n",
    "\n",
    "Materi ini merupakan dasar dari bagaimana operasi citra pada level rendah digunakan untuk berbagai keperluan lain yang banyak dijumpai pada bidang penginderaan jauh. Untuk lebih memahamkan mengenai materi pada minggu ini, kerjakan latihan-latihan di bawah."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KBS5OTq7pyQw"
   },
   "source": [
    "## Latihan Soal\n",
    "\n",
    "1.   Gunakan gambar bebas (bisa foto/cari di internet) dan lakukan **deteksi corner** menggunakan 1) metode Harris dan 2) GFTT. Bandingkan hasil kedua metode tersebut. (Latihan 1)\n",
    "Mana yang lebih baik menurut anda? \n",
    "Mengapa? \n",
    "Berapa jumlah corner yang berhasil dideteksi oleh masing-masing metode?\n",
    "2.   Gunakan gambar bebas (bisa foto/cari di internet) dan lakukan **deteksi keypoint** menggunakan: SIFT, SURF, BRIEF dan ORB. (Latihan 2 dan 3)\n",
    "Mana yang lebih baik menurut anda? \n",
    "Mengapa? \n",
    "Berapa jumlah keypoint yang berhasil dideteksi oleh masing-masing metode?\n",
    "3.   Gunakan gambar bebas (misalnya **wajah masing-masing** , bisa dengan foto/selfie) untuk mendemokan fungsi Feature Detection and Template Matching pada OpenCV. Carilah kondisi optimal dimana teknik tersebut dapat digunakan dengan baik untuk mendeteksi jumlah objek dari foto udara atau citra satelit.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p4ZFOx1-RlRi"
   },
   "source": [
    "## Rujukan\n",
    "\n",
    "* https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_feature2d/py_features_harris/py_features_harris.html\n",
    "* https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_feature2d/py_matcher/py_matcher.html\n",
    "* http://www.acgeospatial.co.uk/template-matching-eo/\n",
    "* https://www.geeksforgeeks.org/template-matching-using-opencv-in-python/ \n",
    "* https://www.pyimagesearch.com/2018/12/17/image-stitching-with-opencv-and-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tF7u-mpNqXD9"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of Minggu 5: Feature Detection.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
